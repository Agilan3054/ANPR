{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4df15df3-6a7f-494b-a0d9-64951fe3d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f5e062c-c475-4866-ac21-bd3bcf4376c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = 'archive (20).zip'\n",
    "extracted_dir = 'extracted_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e1bb22f-da43-4677-aa9a-1bfe5d0d168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "# Extract the contents of the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b2b62e7-e3e5-4159-beb2-06a4a109c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f00adb2a-dcd5-4e81-a43a-50653a1c8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'extracted_data'\n",
    "indian_number_plates_dir = os.path.join(base_dir, 'Indian_Number_Plates')\n",
    "train_dir = indian_number_plates_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45379c54-6c71-492f-86a2-c1857b53ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 128, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a15a5fef-d083-450d-96c3-8c538b48fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed46bdcb-eff8-408b-afd0-1c023f7aea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(height, width),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',  \n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "178b6e0e-c56f-402a-ba14-b9887f2135ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 1 classes.\n",
      "['Sample_Images\\\\Datacluster_number_plates (22).jpg', 'Sample_Images\\\\Datacluster_number_plates (36).jpg', 'Sample_Images\\\\Datacluster_number_plates (38).jpg', 'Sample_Images\\\\Datacluster_number_plates (4).jpg', 'Sample_Images\\\\Datacluster_number_plates (49).jpg', 'Sample_Images\\\\Datacluster_number_plates (5).jpg', 'Sample_Images\\\\Datacluster_number_plates (53).jpg', 'Sample_Images\\\\Datacluster_number_plates (55).jpg', 'Sample_Images\\\\Datacluster_number_plates (62).jpg', 'Sample_Images\\\\Datacluster_number_plates (64).jpg', 'Sample_Images\\\\Datacluster_number_plates (66).jpg', 'Sample_Images\\\\Datacluster_number_plates (70).jpg', 'Sample_Images\\\\Datacluster_number_plates (73).jpg', 'Sample_Images\\\\Datacluster_number_plates (79).jpg', 'Sample_Images\\\\Datacluster_number_plates (80).jpg', 'Sample_Images\\\\Datacluster_number_plates (84).jpg', 'Sample_Images\\\\Datacluster_number_plates (86).jpg', 'Sample_Images\\\\Datacluster_number_plates (89).jpg', 'Sample_Images\\\\Datacluster_number_plates (90).jpg', 'Sample_Images\\\\Datacluster_number_plates (95).jpg', 'Sample_Images\\\\Datacluster_number_plates (96).jpg', 'Sample_Images\\\\Datacluster_number_plates (99).jpg']\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(height, width),\n",
    "    batch_size=32,\n",
    "    class_mode='binary', \n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "print(train_generator.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "104a0de6-a494-4f56-bfa3-d1a5eb7723a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0c30aae-0273-4716-a95f-c7e6bb7d96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef9bf0da-ea12-4d1d-a7ac-68872d08f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e517c30-7799-4fd3-b24f-bf7f3adc0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6340 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 8.6638e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.5339e-06 - accuracy: 1.0000 - val_loss: 2.7254e-10 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.6625e-09 - accuracy: 1.0000 - val_loss: 5.1119e-14 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.2872e-13 - accuracy: 1.0000 - val_loss: 6.5323e-18 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.4231e-16 - accuracy: 1.0000 - val_loss: 6.6237e-22 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.8473e-20 - accuracy: 1.0000 - val_loss: 6.1413e-26 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.8229e-23 - accuracy: 1.0000 - val_loss: 5.8284e-30 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.0239e-27 - accuracy: 1.0000 - val_loss: 6.2347e-34 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.5569e-30 - accuracy: 1.0000 - val_loss: 8.1544e-38 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eb2be67210>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=10, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d9ff566-1eef-4637-a7ad-b2385722c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b159a09a-4378-4dab-954e-81f9befa0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1330778d-3ee9-4513-b684-d52e3ff6862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fad1d36c-4e3a-45d2-9fb0-7ad615773e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = 'num_plate.jpg' \n",
    "test_img = image.load_img(test_img_path, target_size=(height, width))\n",
    "test_img_array = image.img_to_array(test_img)\n",
    "test_img_array /= 255.0\n",
    "test_img_array = np.expand_dims(test_img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbf05520-b6be-4025-8b6a-bc8a6cd0fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_img_array)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69ceaaf8-5bfb-4476-ba59-de5df5481146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "predicted_class = 1 if predictions[0, 0] > threshold else 0\n",
    "print(f'Predicted class: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d656679-6e39-4b00-b91d-4f7cacd584a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b554226-f31f-4f3e-b6dc-5b8db5b44cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3c7ab3-adb2-42bd-9a35-9efe13e502e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = 'num_plate.jpg'\n",
    "img = Image.open(test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bece0f-0964-42bd-8b12-5858160cd9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized text: SS\n",
      "21 BH 2345 AA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(img)\n",
    "\n",
    "print(f'Recognized text: {text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da066a94-69c9-405c-97ca-28174d2f067c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083614a8-eaa3-4fdc-9fc5-52e4762c6372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65e3e4-7e0a-4d61-8157-162fe1990798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f9ba2-1770-44ce-addc-386b87c55434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
